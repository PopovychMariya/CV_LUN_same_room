# CV_LUN_same_room

Проект для класифікації пар знімків (чи та сама кімната) та Telegram-бот, який використовує попередньо навчену модель збережену як TorchScript.

## Копіювання репозиторію
- Склонуйте цей репозиторій і перейдіть у папку проєкту:
  ```bash
  git clone https://github.com/PopovychMariya/CV_LUN_same_room.git
  cd CV_LUN_same_room
  ```
- Далі ви можете працювати або з кореня репозиторію, або одразу переходити в підпапки `research/` (експерименти та підготовка даних) і `classifier/` (готовий бот).

## `path_config.py`: створення структури директорій
Перейдіть до каталогу `research` та запустіть скрипт:
   ```bash
   cd research
   python3 path_config.py
   ```
   Це створить усі папки для датасету, кейпоїнтів, моделей та архівів.
У файлі `research/path_config.py` зібрано всі шляхи, з якими працюють інші скрипти:
   - `DATASET_FOLDER_PATHS` — куди буде завантажено train/test зображення.
   - `DATASET_ANNOTATIONS` — де шукати JSON з анотаціями.
   - `TRAIN_LABELS` — місце для `train_labels.csv`.
   - `DETECTED_KEYPOINTS`, `MODELS_PATH`, `ARCHIVES_PATH` — кеш кейпоїнтів, ваги моделей і zip-архіви.
Якщо дані лежать в іншому місці, просто відредагуйте потрібні шляхи в `path_config.py` перед запуском скриптів. Усі подальші класи/скрипти інтерпретують шляхи з цього файлу.

### Де розміщувати анотації
Скрипти очікують, що:
- тренувальна анотація лежить у `research/dataset/97.json`;
- тестова — у `research/dataset/test_dataset.json`.
Скопіюйте сюди свої JSON-файли або замініть їхні назви у `DATASET_ANNOTATIONS`.

## Завантаження датасету та створення `train_labels.csv`
**Завантажити зображення:** скрипт читає шлях до анотацій з `path_config.py` та розподіляє кожну пару у власну папку `dataset/<task_id>/`.
   ```bash
   python3 research/scripts/download_dataset.py
   ```
   Команда послідовно вантажить train і test згідно з `DATASET_FOLDER_PATHS`.
**Згенерувати таблицю міток:** majority-vote з `answers` пишеться в `dataset/train_labels.csv`.
   ```bash
   python3 research/scripts/make_train_labels_csv.py
   ```

## Архівування даних
Для пакування великих тек із датасетом або проміжними даними скористайтеся `research/scripts/archive_folder.py`.
```bash
python3 research/scripts/archive_folder.py dataset dataset_backup_mar26
```
У результаті в `archives/` з’явиться `dataset_backup_mar26.zip`.

## Telegram-бот
- У каталозі `classifier` зберігається inference-пайплайн і `bot.py`. Запуск:
  ```bash
  python3 classifier/bot.py
  ```
  Під час старту бот викликає `warmup()`, що завантажує TorchScript-модель `models/same_room_binary.ts` й гарантує робочий стан перед обробкою реальних повідомлень.
- Для авторизації потрібно додати файл `classifier/bot_token.py` зі вмістом:
  ```python
  TOKEN = "123456789:ABCDEF..."
  ```


## Архітектура

### Ключові точки та матчинг
- Виявлення/опис: **SuperPoint (max_num_keypoints=1024)** для обох зображень.
- Співставлення: **LightGlue (features="superpoint")** повертає індекси відповідних точок та `match_scores`.
- Inliers: **RANSAC** над гомографією (прапорець `inlier` у ґріді).
- Нормалізація координат: перетворюємо `x, y` у діапазон [0,1] відносно ширини/висоти кожного кадру.

### Подання даних (ґрід 32×32×14)
- Для пари зображень A/B формуємо ґрід 32×32 з 14 каналів:  
  **A (0–6):** `count, conf, dx, dy, cosθ, sinθ, inlier`  
  **B (7–13):** те саме для B (для зсувів — протилежний знак).  
- `conf` — середня впевненість матчів (із LightGlue) у комірці; `count` масштабовано (напр. /1024).  
- Значення в комірках усереднюються по kp; порожні клітинки = 0.

**Деталі каналів (A/B):**
- **count** — кількість kp у комірці. Масштабується (напр. `/1024`), щоб уникати великих діапазонів; за бажанням можна застосувати `log1p`.
- **conf** — середнє значення впевненості матчів LightGlue у комірці (усереднення по всіх kp, що впали в комірку).
- **dx, dy** — зміщення від A до B в нормалізованих координатах `[0,1]`: `dx = x_B − x_A`, `dy = y_B − y_A`.  
  Для половини B записуємо **протилежний знак** (`-dx, -dy`), щоб зберігати антисиметрію ознак відносно напрямку.
- **cosθ, sinθ** — орієнтація зміщення, де `θ = atan2(dy, dx + ε)`; зберігаємо косинус і синус, щоб уникнути проблем з періодичністю кута.  
  Для половини B використовуємо **від’ємні** значення (`-cosθ, -sinθ`) узгоджено зі знаком `dx, dy`.
- **inlier** — частка інлаєрів у комірці (усереднення бінарного прапорця `RANSAC` для кожного матчу).

Примітки:
- Для непорожніх клітинок канали, окрім `count`, **усереднюються по кількості kp** (середні по комірці); порожні клітинки заповнюються нулями.
- Координати `x, y` попередньо нормалізуються у `[0,1]` окремо для кожного зображення; індексація ґріда проводиться округленням до найближчої клітинки з відсіканням на межах.

### Модель
- **Siamese ConvNeXt‑Tiny** з шарингом ваг для гілок A і B; вхід кожної гілки — **[7×32×32]**.  
- Далі: **Global Average Pooling** → конкатенація `[featA, featB]` → **Linear(2D→1)** → логіт.

### Навчання та валідація
- **Loss:** `BCEWithLogitsLoss` з `pos_weight = n_neg / n_pos` по train.  
- **Оптимізація:** AdamW; **Cosine LR**; AMP; clip градієнта = 1.0.  
- Режим: короткий **warm‑up** із замороженим backbone, потім **unfreeze** останніх стадій із меншим LR.  
- **Поріг:** обираємо на **val1** (максимум **F1**), фіксуємо `best_thr`;  
  **Оцінка:** на **val2** лише один прогін з цим `best_thr`.  
- Чекпоінт містить `model_state` та `best_thr`.

### Інференс
- Експорт до **TorchScript**: вхід `(A7, B7)` розміром **[B,7,32,32]**, вихід — **0/1**.  
- Пайплайн: зображення → LightGlue (SuperPoint + LightGlue) → `keypoints_to_grid` → split A/B → TorchScript.  
- У боті модель і матчер ініціалізуються один раз (singletons), виклик — синхронний.

### Обмеження та можливі покращення
- **Без кольорових ознак** втрачається частина інформації про сцену; можна додати кольорові підканали (HSV/LAB-гістограми по комірці, або глобальні кольорові різниці).
- **Схожі об’єкти** можуть породжувати подібні локальні kp і після агрегації у ґрід вводити модель в оману, маркуючи різні кімнати як «ті самі». Пом’якшення: більший радіус агрегації `r`, просторові узгодження, легкі геометричні перевірки.
- Мала роздільна здатність ґріда може втрачати дрібні деталі; симетрійні аугментації (H/V фліп, 90° ротація з корекцією `dx, dy, cos/sin`) дають простий приріст стабільності.
- Збільшення `r=3` та EMA‑усереднення ваг на валідації.
