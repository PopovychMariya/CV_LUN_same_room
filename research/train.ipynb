{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "40293603",
      "metadata": {},
      "source": [
        "## COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a1a0d4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a1a0d4c",
        "outputId": "b4b776ee-f85b-491b-d393-a4db11bc3b8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efc46d38",
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/PopovychMariya/CV_LUN_same_room /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D6tz5n03HolD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6tz5n03HolD",
        "outputId": "de8dec5a-725e-4614-cbbe-cec3410cdc38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CV_LUN_same_room_research\n"
          ]
        }
      ],
      "source": [
        "!cp -r /content/drive/MyDrive/CV_LUN_same_room/research /content/CV_LUN_same_room_research\n",
        "%cd /content/CV_LUN_same_room_research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dz-Y-tesmyg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dz-Y-tesmyg",
        "outputId": "eba06574-080c-4ae0-fd78-c54f3462c249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (11.3.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.19.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.8.0+cu126)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (5.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 7)) (4.13.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 5)) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 5)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 5)) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 5)) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 5)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 5)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 5)) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->-r requirements.txt (line 5)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->-r requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 7)) (2.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 6)) (3.0.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 7)) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 5)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 5)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 5)) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7dda67e",
      "metadata": {
        "id": "c7dda67e"
      },
      "outputs": [],
      "source": [
        "!unzip -qo \"archives/train_images.zip\" -d \"dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ba3a46",
      "metadata": {
        "id": "f4ba3a46"
      },
      "outputs": [],
      "source": [
        "!unzip -qo \"archives/test_images.zip\" -d \"dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "01efc7b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01efc7b8",
        "outputId": "94c78b57-37a3-46b7-cc61-b8f0de729c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing dataloaders...\n",
            "Loading LightGlue weights...\n",
            "Extracting keypoints for test set...\n",
            "Loading batches: 100% 42/42 [02:52<00:00,  4.11s/it]\n",
            "✅ All keypoints detected and saved successfully.\n"
          ]
        }
      ],
      "source": [
        "!python -m lightglue_keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d-zP0taRuLg4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-zP0taRuLg4",
        "outputId": "a5434829-9d72-4f91-c964-52e860c2807e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 2665 files for split 'test'...\n",
            "test split: 100% 2665/2665 [00:38<00:00, 68.57it/s]\n",
            "✅ All grids generated and saved successfully.\n"
          ]
        }
      ],
      "source": [
        "!python -m keypoints_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7df4f99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7df4f99",
        "outputId": "240af475-8dc5-4c9a-b9aa-7a7e3139d7c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive created: /content/CV_LUN_same_room_research/archives/train_keypoints.zip\n"
          ]
        }
      ],
      "source": [
        "!python -m scripts.archive_folder keypoints/train train_keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "qB_itVl95Z5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB_itVl95Z5d",
        "outputId": "8ceb0cc8-3c47-4036-e98f-f9e7671980ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive created: /content/CV_LUN_same_room_research/archives/test_keypoints.zip\n"
          ]
        }
      ],
      "source": [
        "!python -m scripts.archive_folder keypoints/test test_keypoints"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15819e16",
      "metadata": {},
      "source": [
        "## IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dAj9f4X6GcO",
      "metadata": {
        "id": "3dAj9f4X6GcO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uKo1zldo6N-m",
      "metadata": {
        "id": "uKo1zldo6N-m"
      },
      "outputs": [],
      "source": [
        "from path_config import (\n",
        "    ROOT,\n",
        "    DATASET_FOLDER_PATHS,\n",
        "    DATASET_ANNOTATIONS,\n",
        "    TRAIN_LABELS,\n",
        "    DETECTED_KEYPOINTS,\n",
        "    MODELS_PATH\n",
        ")\n",
        "\n",
        "GRID_DIR = DETECTED_KEYPOINTS[\"train\"]\n",
        "\n",
        "LABEL_CSV = TRAIN_LABELS\n",
        "\n",
        "OUT_DIR = ROOT / \"runs\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TRAIN_DIR = DATASET_FOLDER_PATHS[\"train_folder_path\"]\n",
        "TEST_DIR  = DATASET_FOLDER_PATHS[\"test_folder_path\"]\n",
        "TRAIN_ANN = DATASET_ANNOTATIONS[\"train_annotation_path\"]\n",
        "TEST_ANN  = DATASET_ANNOTATIONS[\"test_annotation_path\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fbbc509",
      "metadata": {},
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "048d21d3",
      "metadata": {},
      "source": [
        "## DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "WYxXMd7m5j2C",
      "metadata": {
        "id": "WYxXMd7m5j2C"
      },
      "outputs": [],
      "source": [
        "class GridTrainDataset(Dataset):\n",
        "    def __init__(self, grid_dir: Path, label_csv: Path):\n",
        "        self.grid_dir = Path(grid_dir)\n",
        "        df = pd.read_csv(label_csv)\n",
        "\n",
        "        keep = []\n",
        "        for _, row in df.iterrows():\n",
        "            if (self.grid_dir / row[\"task_id\"] / \"grid_G32.npy\").exists():\n",
        "                keep.append(row)\n",
        "\n",
        "        self.df = pd.DataFrame(keep)\n",
        "        self.task_ids = self.df[\"task_id\"].values\n",
        "        self.labels = self.df[\"label\"].astype(np.float32).values\n",
        "\n",
        "    def __len__(self): return len(self.task_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tid = self.task_ids[idx]\n",
        "        y = self.labels[idx]\n",
        "        grid = np.load(self.grid_dir / tid / \"grid_G32.npy\")\n",
        "        grid = torch.tensor(grid, dtype=torch.float32)\n",
        "        return grid, torch.tensor(y, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "JB7tg-1n7O25",
      "metadata": {
        "id": "JB7tg-1n7O25"
      },
      "outputs": [],
      "source": [
        "class GridTestDataset(Dataset):\n",
        "    def __init__(self, grid_dir: Path):\n",
        "        self.grid_dir = Path(grid_dir)\n",
        "        self.task_ids = sorted([\n",
        "            p.name for p in self.grid_dir.iterdir()\n",
        "            if p.is_dir() and (p / \"grid_G32.npy\").exists()\n",
        "        ])\n",
        "\n",
        "    def __len__(self): return len(self.task_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tid = self.task_ids[idx]\n",
        "        grid = np.load(self.grid_dir / tid / \"grid_G32.npy\")\n",
        "        grid = torch.tensor(grid, dtype=torch.float32)\n",
        "        return grid, tid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SQqpC8n16Img",
      "metadata": {
        "id": "SQqpC8n16Img"
      },
      "outputs": [],
      "source": [
        "# 1) Build dataset + stratified splits (80/10/10)\n",
        "keys = list(DETECTED_KEYPOINTS[\"train\"])                  # ordered ids for your dataset\n",
        "y_all = np.array([TRAIN_LABELS[k] for k in keys], int)    # labels aligned to keys\n",
        "idx_all = np.arange(len(keys))\n",
        "\n",
        "train_idx, temp_idx = train_test_split(\n",
        "\tidx_all, test_size=0.2, stratify=y_all, random_state=SEED\n",
        ")\n",
        "val1_idx, val2_idx = train_test_split(\n",
        "\ttemp_idx, test_size=0.5, stratify=y_all[temp_idx], random_state=SEED\n",
        ")\n",
        "\n",
        "train_full = GridTrainDataset(DETECTED_KEYPOINTS[\"train\"], TRAIN_LABELS)\n",
        "train_ds = Subset(train_full, train_idx.tolist())\n",
        "val1_ds  = Subset(train_full, val1_idx.tolist())\n",
        "val2_ds  = Subset(train_full, val2_idx.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "urPNIXvY9Jpo",
      "metadata": {
        "id": "urPNIXvY9Jpo"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=8, pin_memory=True)\n",
        "val1_loader  = DataLoader(val1_ds, batch_size=32, shuffle=False, num_workers=8, pin_memory=True)\n",
        "val2_loader  = DataLoader(val2_ds, batch_size=32, shuffle=False, num_workers=8, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d042e1b3",
      "metadata": {},
      "source": [
        "## MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fce8d55",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Typed stems (7ch -> 3ch adapter), mask-gated\n",
        "class TypedStem(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.scalar = nn.Sequential(nn.Conv2d(3, 8, 1), nn.GroupNorm(1, 8), nn.GELU())\n",
        "\t\tself.motion = nn.Sequential(nn.Conv2d(2, 16, 3, padding=1), nn.GroupNorm(2, 16), nn.GELU())\n",
        "\t\tself.orient = nn.Sequential(nn.Conv2d(2, 8, 3, padding=1), nn.GroupNorm(1, 8), nn.GELU())\n",
        "\t\tself.drop = nn.Dropout2d(0.10)\n",
        "\t\tself.to3 = nn.Conv2d(8+16+8, 3, 1)\n",
        "\n",
        "\tdef forward(self, x):  # x: [B,7,32,32]\n",
        "\t\tm = (x[:, :1] > 0).float()\n",
        "\t\tsc = self.scalar(torch.cat([x[:,0:1], x[:,1:2], x[:,6:7]], dim=1))\n",
        "\t\tmn = self.motion(x[:,2:4])\n",
        "\t\tang = self.orient(x[:,4:6])\n",
        "\t\th = torch.cat([sc, mn, ang], dim=1) * m\n",
        "\t\th = self.drop(h)\n",
        "\t\treturn self.to3(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4139cbbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) Single-tower ConvNeXt feature encoder to 8x8 map\n",
        "class Tower(nn.Module):\n",
        "\tdef __init__(self, backbone='convnext_tiny', drop_path=0.10):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.stem = TypedStem()\n",
        "\t\tself.bk = timm.create_model(backbone, features_only=True, out_indices=(0,),\n",
        "\t\t                            pretrained=True, drop_path_rate=drop_path)\n",
        "\t\tfor p in self.bk.parameters(): p.requires_grad = False\n",
        "\n",
        "\tdef forward(self, x):  # x: [B,7,32,32]\n",
        "\t\tx = self.stem(x)  # -> [B,3,32,32]\n",
        "\t\tf = self.bk(x)[0] # -> [B,C,8,8]\n",
        "\t\tf = F.normalize(f, dim=1)  # L2 for cosine\n",
        "\t\treturn f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a25a2216",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Local correlation volume (radius r)\n",
        "def local_corr(Fa, Fb, r=2):  # Fa,Fb: [B,C,8,8] -> [B,(2r+1)^2,8,8]\n",
        "\tB, C, H, W = Fa.shape\n",
        "\tpad = F.pad(Fb, (r, r, r, r))\n",
        "\tcosts = []\n",
        "\tfor oy in range(2*r+1):\n",
        "\t\tfor ox in range(2*r+1):\n",
        "\t\t\tsh = pad[:, :, oy:oy+H, ox:ox+W]\n",
        "\t\t\tcosts.append((Fa * sh).sum(1, keepdim=True))\n",
        "\treturn torch.cat(costs, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87c06bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4) 3D cost-volume aggregator -> 2D map\n",
        "class Vol3D(nn.Module):\n",
        "\tdef __init__(self, c_out=16, p_drop=0.10):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.do3d = nn.Dropout3d(p_drop)\n",
        "\t\tself.net = nn.Sequential(\n",
        "\t\t\tnn.Conv3d(1, 8, 3, padding=1), nn.GELU(), nn.GroupNorm(1, 8),\n",
        "\t\t\tnn.Conv3d(8, 8, 3, padding=1), nn.GELU(),\n",
        "\t\t\tnn.Conv3d(8, c_out, 3, padding=1), nn.GELU()\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, vol):  # vol: [B,D,H,W]\n",
        "\t\tv = vol.unsqueeze(1)              # [B,1,D,H,W]\n",
        "\t\tv = self.do3d(v)                  # dropout along D,H,W\n",
        "\t\tv = self.net(v)                   # [B,Cd,D,H,W]\n",
        "\t\treturn v.mean(2)                  # -> [B,Cd,H,W]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8bd6c9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5) Fusion + head\n",
        "class FusionHead(nn.Module):\n",
        "\tdef __init__(self, c_in_bk, c_vol=16, width=64, p_drop=0.20):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.pa = nn.Conv2d(c_in_bk, 16, 1)\n",
        "\t\tself.pb = nn.Conv2d(c_in_bk, 16, 1)\n",
        "\t\tself.pd = nn.Conv2d(c_in_bk, 16, 1)\n",
        "\t\tself.mix = nn.Conv2d(c_vol + 48, width, 1)\n",
        "\t\tself.drop = nn.Dropout(p_drop)\n",
        "\t\tself.mlp = nn.Sequential(nn.Linear(width, width//2), nn.GELU(), nn.Linear(width//2, 1))\n",
        "\n",
        "\tdef forward(self, agg2d, Fa, Fb):\n",
        "\t\tf = torch.cat([agg2d, self.pa(Fa), self.pb(Fb), self.pd(Fa - Fb)], dim=1)\n",
        "\t\tz = self.mix(f).mean(dim=(2,3))\n",
        "\t\tz = self.drop(z)\n",
        "\t\treturn self.mlp(z).squeeze(1)  # [B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a29779c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6) Full pair model\n",
        "class PairSameRoomModel(nn.Module):\n",
        "\tdef __init__(self, backbone='convnext_tiny', r=2):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.towerA = Tower(backbone)\n",
        "\t\tself.towerB = Tower(backbone)\n",
        "\t\t# peek a dummy to get backbone out-channels\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tc_bk = timm.create_model(backbone, features_only=True, out_indices=(0,), pretrained=False)(torch.zeros(1,3,32,32))[0].shape[1]\n",
        "\t\tself.r = r\n",
        "\t\tself.vol = Vol3D(c_out=16)\n",
        "\t\tself.head = FusionHead(c_in_bk=c_bk, c_vol=16, width=64)\n",
        "\n",
        "\tdef freeze_backbone(self, freeze=True):\n",
        "\t\tfor t in [self.towerA.bk, self.towerB.bk]:\n",
        "\t\t\tfor p in t.parameters(): p.requires_grad = not (freeze)\n",
        "\n",
        "\tdef forward(self, A7, B7):  # [B,7,32,32] each\n",
        "\t\tFa = self.towerA(A7)\n",
        "\t\tFb = self.towerB(B7)\n",
        "\t\tvol = local_corr(Fa, Fb, r=self.r)  # [B,D,8,8]\n",
        "\t\tagg = self.vol(vol)                 # [B,16,8,8]\n",
        "\t\treturn self.head(agg, Fa, Fb)       # logits [B]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c07f18aa",
      "metadata": {},
      "source": [
        "## TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5af22a9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = PairSameRoomModel(backbone='convnext_tiny', r=2).to(DEVICE)\n",
        "model.freeze_backbone(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb4deff9",
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "lr, wd = 3e-4, 1e-2\n",
        "eta_min = 1e-6\n",
        "steps_per_epoch = len(train_loader)\n",
        "total_steps = epochs * steps_per_epoch\n",
        "warmup_steps = max(1, int(0.1 * total_steps))\n",
        "ckpt_path = MODELS_PATH / \"best_convnext_siamese.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25197d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = y_all[train_idx]\n",
        "n_pos = int((y_train == 1).sum())\n",
        "n_neg = int((y_train == 0).sum())\n",
        "pos_weight_value = n_neg / max(n_pos, 1)\n",
        "\n",
        "print(f\"[train] pos={n_pos}, neg={n_neg}, pos_weight={pos_weight_value:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9fbce4",
      "metadata": {},
      "outputs": [],
      "source": [
        "crit  = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_value], device=DEVICE))\n",
        "opt   = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=(0.9, 0.999))\n",
        "sched = SequentialLR(\n",
        "\topt,\n",
        "\tschedulers=[\n",
        "\t\tLinearLR(opt, start_factor=1e-3, end_factor=1.0, total_iters=warmup_steps),\n",
        "\t\tCosineAnnealingLR(opt, T_max=total_steps - warmup_steps, eta_min=eta_min),\n",
        "\t],\n",
        "\tmilestones=[warmup_steps],\n",
        ")\n",
        "scaler = GradScaler(enabled=(DEVICE.type == 'cuda'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af92792b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_step(batch, clip=1.0):\n",
        "\tmodel.train()\n",
        "\tA7, B7, y = batch\n",
        "\tA7, B7, y = A7.to(DEVICE), B7.to(DEVICE), y.float().to(DEVICE)\n",
        "\n",
        "\topt.zero_grad(set_to_none=True)\n",
        "\twith autocast(enabled=scaler is not None):\n",
        "\t\tlogits = model(A7, B7)\n",
        "\t\tloss = crit(logits, y)\n",
        "\n",
        "\tif scaler is None:\n",
        "\t\tloss.backward()\n",
        "\t\tnn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\t\topt.step()\n",
        "\telse:\n",
        "\t\tscaler.scale(loss).backward()\n",
        "\t\tscaler.unscale_(opt)\n",
        "\t\tnn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\t\tscaler.step(opt); scaler.update()\n",
        "\n",
        "\tsched.step()\n",
        "\treturn float(loss.detach()), opt.param_groups[0]['lr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65805b94",
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_proba(model, loader, device=DEVICE):\n",
        "\tmodel.eval()\n",
        "\tps, ys = [], []\n",
        "\tfor A7, B7, y in loader:\n",
        "\t\tp = torch.sigmoid(model(A7.to(device), B7.to(device))).cpu()\n",
        "\t\tps.append(p); ys.append(y.cpu().float())\n",
        "\treturn torch.cat(ps), torch.cat(ys)\n",
        "\n",
        "def f1_pr_rec_at_threshold(p, y, thr):\n",
        "\tif hasattr(p, \"detach\"): p = p.detach().cpu().numpy()\n",
        "\tif hasattr(y, \"detach\"): y = y.detach().cpu().numpy().astype(int)\n",
        "\tpb = (p >= thr).astype(int)\n",
        "\treturn (\n",
        "\t\tfloat(f1_score(y, pb, zero_division=0)),\n",
        "\t\tfloat(precision_score(y, pb, zero_division=0)),\n",
        "\t\tfloat(recall_score(y, pb, zero_division=0)),\n",
        "\t)\n",
        "\n",
        "def pick_best_threshold(p, y):\n",
        "\tif hasattr(p, \"detach\"): p = p.detach().cpu().numpy()\n",
        "\tif hasattr(y, \"detach\"): y = y.detach().cpu().numpy().astype(int)\n",
        "\n",
        "\tprec, rec, th = precision_recall_curve(y, p)\n",
        "\tf1 = 2*prec*rec/(prec+rec+1e-9)\n",
        "\tf1_t = f1[1:]\n",
        "\ti = int(np.nanargmax(f1_t))\n",
        "\treturn {\"thr\": float(th[i]), \"f1\": float(f1_t[i]),\n",
        "\t        \"prec\": float(prec[i+1]), \"rec\": float(rec[i+1])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "488ea8d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_ckpt(path, model, opt, epoch, best_thr, best_val1_f1, backbone='convnext_tiny', r=2):\n",
        "    torch.save({\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": opt.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"best_thr\": float(best_thr),\n",
        "        \"best_val1_f1\": float(best_val1_f1),\n",
        "        \"config\": {\"backbone\": backbone, \"r\": r}\n",
        "    }, path)\n",
        "\n",
        "def load_ckpt(path, model, opt=None, map_location=\"cpu\"):\n",
        "\tdata = torch.load(path, map_location=map_location)\n",
        "\tmodel.load_state_dict(data[\"model_state\"])\n",
        "\tif opt is not None and \"optimizer_state\" in data:\n",
        "\t\topt.load_state_dict(data[\"optimizer_state\"])\n",
        "\treturn data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "142aa268",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_f1, best_thr = 0.0, 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72bf3673",
      "metadata": {},
      "outputs": [],
      "source": [
        "for ep in range(1, epochs+1):\n",
        "    # ---- train ----\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    for batch in train_loader:\n",
        "        loss, lr = train_step(batch)\n",
        "        running += loss\n",
        "    avg_loss = running / max(1, len(train_loader))\n",
        "\n",
        "    # ---- val1: pick threshold ----\n",
        "    p1, y1 = predict_proba(model, val1_loader)\n",
        "    sel = pick_best_threshold(p1, y1)\n",
        "    best_thr = sel[\"thr\"]\n",
        "    val1_f1, val1_pr, val1_rc = sel[\"f1\"], sel[\"prec\"], sel[\"rec\"]\n",
        "\n",
        "    # ---- val2: evaluate at that threshold ----\n",
        "    p2, y2 = predict_proba(model, val2_loader)\n",
        "    val2_f1, val2_pr, val2_rc = f1_pr_rec_at_threshold(p2, y2, best_thr)\n",
        "\n",
        "    # ---- log ----\n",
        "    print(f\"Epoch {ep:03d} | loss {avg_loss:.4f} | lr {lr:.2e} | \"\n",
        "            f\"val1 F1 {val1_f1:.4f} @ {best_thr:.2f} (P {val1_pr:.3f}, R {val1_rc:.3f}) | \"\n",
        "            f\"val2 F1 {val2_f1:.4f} (P {val2_pr:.3f}, R {val2_rc:.3f})\")\n",
        "\n",
        "    # ---- checkpoint on val1 F1 improvement ----\n",
        "    if val1_f1 > best_f1 + 1e-6:\n",
        "        best_f1 = val1_f1\n",
        "        save_ckpt(ckpt_path, model, opt, ep, best_thr, best_f1)\n",
        "        # optional: keep a 'best' symlink/name if you’re civilized\n",
        "\n",
        "print(f\"Best val1 F1={best_f1:.4f} at thr={best_thr:.2f}. \"\n",
        "        f\"Checkpoint saved to {os.path.abspath(ckpt_path)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
